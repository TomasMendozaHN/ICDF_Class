{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "05252022_Main.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOO6sQ47LC//5qGNlXXzMSV",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/TomasMendozaHN/ICDF_Class/blob/main/05252022_Main.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Mount my Google Drive!"
      ],
      "metadata": {
        "id": "Rb192_J3JjCa"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NQuVhEg_uSqB"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Run the YOLO v3 Notebook we created earlier!"
      ],
      "metadata": {
        "id": "cLQPxK7ZJhTQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%run /content/gdrive/MyDrive/Colab\\ Notebooks/05252022_YOLO_V3.ipynb"
      ],
      "metadata": {
        "id": "UNGLGz3puatE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Run the Webcam Notebook to handle our webcam!"
      ],
      "metadata": {
        "id": "Ea65749oJeph"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%run /content/drive/MyDrive/Colab\\ Notebooks/05252022_WebCam.ipynb"
      ],
      "metadata": {
        "id": "u_tcaeFWu7zF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "video_stream()\n",
        "# label for video\n",
        "label_html = 'Capturing...'\n",
        "# initialze bounding box to empty\n",
        "bbox = ''\n",
        "count = 0 \n",
        "while True:\n",
        "    js_reply = video_frame(label_html, bbox)\n",
        "    if not js_reply:\n",
        "        break\n",
        "\n",
        "    # convert JS response to OpenCV Image\n",
        "    img = js_to_image(js_reply[\"img\"])\n",
        "\n",
        "    # create transparent overlay for bounding box\n",
        "    bbox_array = np.zeros([480,640,4], dtype=np.uint8)\n",
        "\n",
        "    # Convert back to image!\n",
        "    bbox_array[:,:,3] = (bbox_array.max(axis = 2) > 0 ).astype(int) * 255\n",
        "    # convert overlay of bbox into bytes\n",
        "    bbox_bytes = bbox_to_bytes(bbox_array)\n",
        "\n",
        "    # update bbox so next frame gets new overlay\n",
        "    bbox = bbox_bytes"
      ],
      "metadata": {
        "id": "4ksl9ZEIEXyI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Draw figures on frame"
      ],
      "metadata": {
        "id": "OH_AT2SyR7Yr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Draw Figures\n",
        "# cv2 rectangle (img, (xmin, ymin), (xmax, ymax), color, border_thickness)\n",
        "\n",
        "# cv2 circle (img, ((x_center, y_center)), radius, color, border_thickness)\n",
        "\n",
        "# cv2 triangle!\n",
        "cv2.line(bbox_array, (300,300), (330,250), (0, 0, 255), 3)"
      ],
      "metadata": {
        "id": "QJYB8y-hR78V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Canny Edge Detector\n"
      ],
      "metadata": {
        "id": "qMDeCrOTUrhg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import clear_output \n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "\n",
        "# start streaming video from webcam\n",
        "video_stream()\n",
        "# label for video\n",
        "label_html = 'Capturing...'\n",
        "# initialze bounding box to empty\n",
        "bbox = ''\n",
        "count = 0 \n",
        "while True:\n",
        "    js_reply = video_frame(label_html, bbox)\n",
        "    if not js_reply:\n",
        "        break\n",
        "\n",
        "    # convert JS response to OpenCV Image\n",
        "    img = js_to_image(js_reply[\"img\"])\n",
        "\n",
        "    # Apply Canny Edge Detector\n",
        "    canny = cv2.Canny(img, 10, 200)\n",
        "\n",
        "    clear_output(wait=True)\n",
        "    cv2_imshow(canny)"
      ],
      "metadata": {
        "id": "CvuUKojWUryd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Perform simple face detection on the stream :)"
      ],
      "metadata": {
        "id": "9k2ZBB7wKdfx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load Face Detection network\n",
        "face_cascade = cv2.CascadeClassifier(cv2.samples.findFile(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml'))"
      ],
      "metadata": {
        "id": "p7aQuzhOKvdi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# start streaming video from webcam\n",
        "video_stream()\n",
        "# label for video\n",
        "label_html = 'Capturing...'\n",
        "# initialze bounding box to empty\n",
        "bbox = ''\n",
        "count = 0 \n",
        "while True:\n",
        "    js_reply = video_frame(label_html, bbox)\n",
        "    if not js_reply:\n",
        "        break\n",
        "\n",
        "    # convert JS response to OpenCV Image\n",
        "    img = js_to_image(js_reply[\"img\"])\n",
        "\n",
        "    # create transparent overlay for bounding box\n",
        "    bbox_array = np.zeros([480,640,4], dtype=np.uint8)\n",
        "\n",
        "    # grayscale image for face detection\n",
        "    gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
        "\n",
        "    # get face region coordinates\n",
        "    faces = face_cascade.detectMultiScale(gray)\n",
        "    # get face bounding box for overlay\n",
        "    for (x,y,w,h) in faces:\n",
        "      bbox_array = cv2.rectangle(bbox_array,(x,y),(x+w,y+h),(255,0,0),2)\n",
        "\n",
        "    bbox_array[:,:,3] = (bbox_array.max(axis = 2) > 0 ).astype(int) * 255\n",
        "    # convert overlay of bbox into bytes\n",
        "    bbox_bytes = bbox_to_bytes(bbox_array)\n",
        "    # update bbox so next frame gets new overlay\n",
        "    bbox = bbox_bytes"
      ],
      "metadata": {
        "id": "Sd1ptdCEDC3q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Perform FasterRCNN on Steam"
      ],
      "metadata": {
        "id": "5_2meetsLMr7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torchvision\n",
        "import torch\n",
        "\n",
        "# First, load pre-trained faster RCNN model\n",
        "model = torchvision.models.detection.fasterrcnn_resnet50_fpn(\n",
        "                                                pretrained=True, \n",
        "                                                box_nms_thresh=0.5\n",
        "                                                )\n",
        "\n",
        "# Then send to CUDA and set to evaluation mode!\n",
        "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
        "model.to(device)\n",
        "model.eval()\n",
        "print(\"FasterRCNN Model Ready!\")"
      ],
      "metadata": {
        "id": "dzBAHyzULKv1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# start streaming video from webcam\n",
        "video_stream()\n",
        "# label for video\n",
        "label_html = 'Capturing...'\n",
        "# initialze bounding box to empty\n",
        "bbox = ''\n",
        "count = 0 \n",
        "while True:\n",
        "    js_reply = video_frame(label_html, bbox)\n",
        "    if not js_reply:\n",
        "        break\n",
        "\n",
        "    # convert JS response to OpenCV Image\n",
        "    img = js_to_image(js_reply[\"img\"])\n",
        "    img = img.astype(float) / 255\n",
        "\n",
        "    # Convert image to tensor\n",
        "    img = img.transpose((2,0,1))\n",
        "    img = img[None,...]\n",
        "    img = torch.as_tensor(img, dtype=torch.float32).to(device)\n",
        "\n",
        "    # create transparent overlay for bounding box\n",
        "    bbox_array = np.zeros([480,640,4], dtype=np.uint8)\n",
        "\n",
        "    # get face region coordinates\n",
        "    outputs = model(img)\n",
        "\n",
        "    boxes = outputs[0]['boxes']\n",
        "    labels = outputs[0]['labels']\n",
        "\n",
        "    boxes, labels = boxes.detach().cpu().numpy(), labels.detach().cpu().numpy()\n",
        "\n",
        "    # Filter out boxes for Class = 1 (person)\n",
        "    boxes = [x for x,y in zip(boxes,labels) if y==1]\n",
        "\n",
        "    for (x,y,w,h) in boxes:\n",
        "      bbox_array = cv2.rectangle(bbox_array,(x,y),(w+x,h+y),(255,0,0),2)\n",
        "\n",
        "    bbox_array[:,:,3] = (bbox_array.max(axis = 2) > 0 ).astype(int) * 255\n",
        "    # convert overlay of bbox into bytes\n",
        "    bbox_bytes = bbox_to_bytes(bbox_array)\n",
        "    # update bbox so next frame gets new overlay\n",
        "    bbox = bbox_bytes"
      ],
      "metadata": {
        "id": "936TqaFDLQnw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "aw8HkEJXR4-Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "TrtnxkCYXwaf"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}